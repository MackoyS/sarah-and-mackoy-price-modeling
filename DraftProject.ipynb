{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mackoy & Sarah Project Title Here \n",
    "## Sub Heading Here \n",
    "### Description of Project (Goals, Stakes, Summarize Findings Here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstake holder: residential real estate \\nwe can fram our analysis around pitching high end house vs. middle class housing \\nPRICE WILL ALWAYS BE OUR DEPENDENT VARI \\nindepentdent variables include but are not limitied  to: waterfront, beds & baths, grade (sarah loves zipcodes so i can experiment with those on my own <3)\\n\\n        2015 is our most recent year, our data just covers 1 year p  much 2014-2015\\n        \\n9/11 update: price, sqft_living, zipcode, living15, lot15, bedrooms, bathrooms, floors, keep condition & grade,  yr_built \\n\\nwe can feature engineer a bedroom/bathroom ratio \\n\\n\\n\"divising a model that can help predict purchase price based on the attributes of the home --> so firms can better prepare their client for the pre-approval process\"\\n\\nStakeholder\\nA Real Estate Company\\nBusiness problem\\nDevising a model that can help predict purchase price according to attributes of a home.\\nThis way they can prepare their clients early on for what pre-approval amount they need.\\nEDA\\nRemoved Nulls\\nFilled in empty values with unknown\\nRemoved columns that didn’t have information we would use.\\nRemoved outliers through 3 standard deviations.\\nFor each column, it first computes the Z-score of each value in the column, relative to the column mean and standard deviation. It then takes the absolute Z-score because the direction does not matter, only if it is below the threshold. all(axis=1) ensures that for each row, all column satisfy the constraint. Finally, the result of this condition is used to index the dataframe.\\nFirst simple model\\nCreated a simple model based on price and square foot as that had the highest correlation.\\nModeling process\\nStill honing in on what predictors to use for our multilinear regression.\\nNeed to make sure we check the assumptions before finalizing this.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE TO SELVES \n",
    "\"\"\"\n",
    "stake holder: residential real estate \n",
    "we can fram our analysis around pitching high end house vs. middle class housing \n",
    "PRICE WILL ALWAYS BE OUR DEPENDENT VARI \n",
    "indepentdent variables include but are not limitied  to: waterfront, beds & baths, grade (sarah loves zipcodes so i can experiment with those on my own <3)\n",
    "\n",
    "        2015 is our most recent year, our data just covers 1 year p  much 2014-2015\n",
    "        \n",
    "9/11 update: price, sqft_living, zipcode, living15, lot15, bedrooms, bathrooms, floors, keep condition & grade,  yr_built \n",
    "\n",
    "we can feature engineer a bedroom/bathroom ratio \n",
    "\n",
    "\n",
    "\"divising a model that can help predict purchase price based on the attributes of the home --> so firms can better prepare their client for the pre-approval process\"\n",
    "\n",
    "Stakeholder\n",
    "A Real Estate Company\n",
    "Business problem\n",
    "Devising a model that can help predict purchase price according to attributes of a home.\n",
    "This way they can prepare their clients early on for what pre-approval amount they need.\n",
    "EDA\n",
    "Removed Nulls\n",
    "Filled in empty values with unknown\n",
    "Removed columns that didn’t have information we would use.\n",
    "Removed outliers through 3 standard deviations.\n",
    "For each column, it first computes the Z-score of each value in the column, relative to the column mean and standard deviation. It then takes the absolute Z-score because the direction does not matter, only if it is below the threshold. all(axis=1) ensures that for each row, all column satisfy the constraint. Finally, the result of this condition is used to index the dataframe.\n",
    "First simple model\n",
    "Created a simple model based on price and square foot as that had the highest correlation.\n",
    "Modeling process\n",
    "Still honing in on what predictors to use for our multilinear regression.\n",
    "Need to make sure we check the assumptions before finalizing this.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/kc_house_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>2.159700e+04</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>17755.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "      <td>21597.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580474e+09</td>\n",
       "      <td>5.402966e+05</td>\n",
       "      <td>3.373200</td>\n",
       "      <td>2.115826</td>\n",
       "      <td>2080.321850</td>\n",
       "      <td>1.509941e+04</td>\n",
       "      <td>1.494096</td>\n",
       "      <td>1788.596842</td>\n",
       "      <td>1970.999676</td>\n",
       "      <td>83.636778</td>\n",
       "      <td>98077.951845</td>\n",
       "      <td>47.560093</td>\n",
       "      <td>-122.213982</td>\n",
       "      <td>1986.620318</td>\n",
       "      <td>12758.283512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876736e+09</td>\n",
       "      <td>3.673681e+05</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.768984</td>\n",
       "      <td>918.106125</td>\n",
       "      <td>4.141264e+04</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>827.759761</td>\n",
       "      <td>29.375234</td>\n",
       "      <td>399.946414</td>\n",
       "      <td>53.513072</td>\n",
       "      <td>0.138552</td>\n",
       "      <td>0.140724</td>\n",
       "      <td>685.230472</td>\n",
       "      <td>27274.441950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.800000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.220000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471100</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.231000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068500e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.159700e+04  2.159700e+04  21597.000000  21597.000000  21597.000000   \n",
       "mean   4.580474e+09  5.402966e+05      3.373200      2.115826   2080.321850   \n",
       "std    2.876736e+09  3.673681e+05      0.926299      0.768984    918.106125   \n",
       "min    1.000102e+06  7.800000e+04      1.000000      0.500000    370.000000   \n",
       "25%    2.123049e+09  3.220000e+05      3.000000      1.750000   1430.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    sqft_above      yr_built  yr_renovated  \\\n",
       "count  2.159700e+04  21597.000000  21597.000000  21597.000000  17755.000000   \n",
       "mean   1.509941e+04      1.494096   1788.596842   1970.999676     83.636778   \n",
       "std    4.141264e+04      0.539683    827.759761     29.375234    399.946414   \n",
       "min    5.200000e+02      1.000000    370.000000   1900.000000      0.000000   \n",
       "25%    5.040000e+03      1.000000   1190.000000   1951.000000      0.000000   \n",
       "50%    7.618000e+03      1.500000   1560.000000   1975.000000      0.000000   \n",
       "75%    1.068500e+04      2.000000   2210.000000   1997.000000      0.000000   \n",
       "max    1.651359e+06      3.500000   9410.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21597.000000  21597.000000  21597.000000   21597.000000   21597.000000  \n",
       "mean   98077.951845     47.560093   -122.213982    1986.620318   12758.283512  \n",
       "std       53.513072      0.138552      0.140724     685.230472   27274.441950  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471100   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.231000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#check for missing data \n",
    "data.info()\n",
    "#waterfront missing 2,376\n",
    "#view missing 63 values\n",
    "#year reno missing 3,842\n",
    "\n",
    "\n",
    "# date is an object --> put that into date time \n",
    "# sqft_basement is an object --> put that into numeric & there aree also missing valyes (bc there is no basement)\n",
    "#whats up with year reno \n",
    "#water front has missing too \n",
    "# we can dummy: \n",
    "    # water front \n",
    "    # condition \n",
    "    # grade\n",
    "    # zipcode \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE         19422\n",
       "AVERAGE        957\n",
       "GOOD           508\n",
       "FAIR           330\n",
       "EXCELLENT      317\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NULLS \n",
    "# water front had 19221/21597\n",
    "# view has 21534 / 21597 --> 19422 had \"none\" for view; only 2,112 values had a view \n",
    "# yr_reno had 117755/21597\n",
    "data['view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.000000\n",
       "sqft_living      0.701917\n",
       "sqft_above       0.605368\n",
       "sqft_living15    0.585241\n",
       "bathrooms        0.525906\n",
       "bedrooms         0.308787\n",
       "lat              0.306692\n",
       "floors           0.256804\n",
       "yr_renovated     0.129599\n",
       "sqft_lot         0.089876\n",
       "sqft_lot15       0.082845\n",
       "yr_built         0.053953\n",
       "zipcode          0.053402\n",
       "long             0.022036\n",
       "id               0.016772\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at correlations \n",
    "\n",
    "potential_corrs = data.corr()['price'].map(abs).sort_values(ascending=False)\n",
    "potential_corrs\n",
    "\n",
    "#looks like: price & sqft_living has the biggest impact also sqft_above, bathroom is p good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Cleaning Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              21597 non-null  int64  \n",
      " 1   price           21597 non-null  float64\n",
      " 2   bedrooms        21597 non-null  int64  \n",
      " 3   bathrooms       21597 non-null  float64\n",
      " 4   sqft_living     21597 non-null  int64  \n",
      " 5   sqft_lot        21597 non-null  int64  \n",
      " 6   floors          21597 non-null  float64\n",
      " 7   sqft_above      21597 non-null  int64  \n",
      " 8   sqft_living15   21597 non-null  int64  \n",
      " 9   sqft_lot15      21597 non-null  int64  \n",
      " 10  grade_num       21597 non-null  object \n",
      " 11  bed_bath_ratio  21597 non-null  float64\n",
      " 12  zip_city        21597 non-null  int32  \n",
      " 13  Waterfront      21597 non-null  uint8  \n",
      " 14  mean_price      21597 non-null  float64\n",
      "dtypes: float64(5), int32(1), int64(7), object(1), uint8(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# lets start cleaning! get your mop & broom! \n",
    "\n",
    "#make a copy of the dataset, we never want to overwrite our OG data \n",
    "df = data.copy()\n",
    "#convert date to date time \n",
    "df['date'] = pd.to_datetime(data['date'])\n",
    "# pull out grade code \n",
    "df['grade_num'] = data['grade'].map(lambda x:x.split(' ', 1)[0])\n",
    "#bed bath ratio \n",
    "df['bed_bath_ratio'] = df['bedrooms']/df['bathrooms']\n",
    "#dropping unnecessary columns \n",
    "df = df.drop(columns = ['sqft_basement', 'yr_renovated', 'lat', 'long', 'view', 'condition','grade', 'date'])\n",
    "\n",
    "\n",
    "#let's dummy variable for city --> 1 for in city of seatlle, 0 for outside of city limits \n",
    "#creating a list of zipcodes thar are IN the city limits of seatlle\n",
    "zip_city_list = [98101, 98177, 98133, 98155, 98125, 98117, 98103, 98107, 98105, 98195, 98199, 98119, 98109, 98102, 98112, 98121, 98122, 98104, 98134, 98144, 98136, 98126, 98106, 98108, 98118, 98146, 98178]\n",
    "#if it is within our city limits give it a 1,without give it 0 \n",
    "df['zip_city'] = np.where(df['zipcode'].isin(zip_city_list),1,0)\n",
    "\n",
    "\n",
    "\n",
    "#let’s dummy waterfront\n",
    "# assumotion: ATM it’s that it’s unknown\n",
    "    #NaN meaning?--> express this as a % of missing --> report this as a data limitation; llimitations might be that some of the nans might have unreported waterfronts, based off this analyssis we will do --> we could do a ttest with a random sample of Nans and see how mnay of them do have a water front --> we have this % certainty that these nans are nos\n",
    "df['waterfront'] = df['waterfront'].fillna('Unknown')\n",
    "#getting dummy variables for waterfront 0= no water, 1 = yes\n",
    "df1 = pd.get_dummies(df['waterfront'])\n",
    "#adding dummies into a main dataframe\n",
    "main_df = pd.concat([df, df1], axis=1)\n",
    "#cleaning up the columns so that we have a cleam copy\n",
    "main_df['Waterfront'] = main_df['YES'].copy()\n",
    "#dropping unneeded columns\n",
    "main_df = main_df.drop(columns = ['NO', 'Unknown', 'YES', 'waterfront', 'zipcode', 'yr_built'])\n",
    "#store the mean of price because that is the best predictor\n",
    "mean_price = main_df['price'].mean()\n",
    "main_df['mean_price'] = main_df['price'].mean()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dropping basement bc there was a lot of missing --> put in that metric\n",
    "dropping reno bc there was a lot missing --> put in that metric \n",
    "dropping lat & long bc we don't need them --> going with zipcode; bc of redudancy --> 3 variables capture 1 \n",
    "dropping view with none & view doesn't really mean anything --> find the breakdown % of homes that have views and waterfronts --> view might mean something in terms of price --> are water front and view multicol\n",
    "dropping condition bc a lack of spread --> put metric in here\n",
    "drop sqftbasement bc of too many missing values & lack of data sic \n",
    "\"\"\"\n",
    "\n",
    "main_df.info()\n",
    "#print(mean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19479 entries, 0 to 21596\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   price           19479 non-null  float64\n",
      " 1   bedrooms        19479 non-null  float64\n",
      " 2   bathrooms       19479 non-null  float64\n",
      " 3   sqft_living     19479 non-null  float64\n",
      " 4   sqft_lot        19479 non-null  float64\n",
      " 5   floors          19479 non-null  float64\n",
      " 6   sqft_above      19479 non-null  float64\n",
      " 7   sqft_living15   19479 non-null  float64\n",
      " 8   sqft_lot15      19479 non-null  float64\n",
      " 9   grade_num       19479 non-null  float64\n",
      " 10  bed_bath_ratio  19479 non-null  float64\n",
      " 11  mean_price      19479 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "#make a copy of the clean dataframe\n",
    "no_out = main_df.copy()\n",
    "#drop columns that we cannot use\n",
    "no_out = no_out.drop(columns= ['id', 'zip_city', 'Waterfront'], axis=1)\n",
    "#change data type so that we can math\n",
    "no_out = no_out.astype('float')\n",
    "#pull out the columns\n",
    "columns = no_out.columns\n",
    "#for each column in the dataframe, get the mean and standard deviation\n",
    "#then get the z-score for within 3 standard devaitions\n",
    "for col in columns:\n",
    "        mean = no_out[col].mean()\n",
    "        sd = no_out[col].std()\n",
    "        no_out = no_out[(no_out[col] <= mean+(3*sd))]\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "no_out.info()\n",
    "#part of this loop is courtesy of Stephen Allwright\n",
    "#https://stephenallwright.com/remove-outliers-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19479 entries, 0 to 21596\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   price           19479 non-null  float64\n",
      " 1   bedrooms        19479 non-null  float64\n",
      " 2   bathrooms       19479 non-null  float64\n",
      " 3   sqft_living     19479 non-null  float64\n",
      " 4   sqft_lot        19479 non-null  float64\n",
      " 5   floors          19479 non-null  float64\n",
      " 6   sqft_above      19479 non-null  float64\n",
      " 7   sqft_living15   19479 non-null  float64\n",
      " 8   sqft_lot15      19479 non-null  float64\n",
      " 9   grade_num       19479 non-null  float64\n",
      " 10  bed_bath_ratio  19479 non-null  float64\n",
      " 11  mean_price      19479 non-null  float64\n",
      " 12  id              19479 non-null  int64  \n",
      " 13  zip_city        19479 non-null  int32  \n",
      " 14  Waterfront      19479 non-null  uint8  \n",
      "dtypes: float64(12), int32(1), int64(1), uint8(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "#add the no_out data back into the full clean dataframe\n",
    "not_out = main_df.copy()\n",
    "#drop the columns that we have cleaned for outliers\n",
    "not_out = not_out.drop(columns= ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'sqft_above', 'sqft_living15', 'sqft_lot15', 'grade_num', 'bed_bath_ratio','mean_price'], axis=1)\n",
    "#add the outliers & no-outlier data frames together so that we have all our columns again\n",
    "clean_df = pd.concat([no_out, not_out], axis=1)\n",
    "#drop the null values (for the columns that we did not do the outlier math on )\n",
    "clean_df = clean_df.dropna()\n",
    "#check to make sure that we have all our columns with the same amount of data\n",
    "clean_df.info()\n",
    "#store our cleaned data as a csv file for future use\n",
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.00000\n",
       "grade_num        0.61383\n",
       "sqft_living      0.60783\n",
       "sqft_living15    0.53187\n",
       "sqft_above       0.48465\n",
       "bathrooms        0.43632\n",
       "bedrooms         0.30181\n",
       "floors           0.24139\n",
       "bed_bath_ratio   0.23746\n",
       "sqft_lot15       0.07954\n",
       "sqft_lot         0.07637\n",
       "mean_price       0.00000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at some corrs \n",
    "potential_corrs = no_out.corr()['price'].map(abs).sort_values(ascending=False)\n",
    "potential_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Baseline Model: Mean Price\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyRegressor()\n",
      "0.0\n",
      "[488722.0910211 488722.0910211 488722.0910211 ... 488722.0910211\n",
      " 488722.0910211 488722.0910211]\n",
      "<bound method Series.mean of 0       221900.00000\n",
      "1       538000.00000\n",
      "2       180000.00000\n",
      "3       604000.00000\n",
      "4       510000.00000\n",
      "            ...     \n",
      "21592   360000.00000\n",
      "21593   400000.00000\n",
      "21594   402101.00000\n",
      "21595   400000.00000\n",
      "21596   325000.00000\n",
      "Name: price, Length: 19479, dtype: float64>\n",
      "0       -266822.09102\n",
      "1         49277.90898\n",
      "2       -308722.09102\n",
      "3        115277.90898\n",
      "4         21277.90898\n",
      "             ...     \n",
      "21592   -128722.09102\n",
      "21593    -88722.09102\n",
      "21594    -86621.09102\n",
      "21595    -88722.09102\n",
      "21596   -163722.09102\n",
      "Name: price, Length: 19479, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummymodel = DummyRegressor(strategy = 'mean')\n",
    "\n",
    "X = no_out.drop(labels = ['grade_num', 'mean_price'], axis=1)\n",
    "y = no_out.price\n",
    "\n",
    "print(dummymodel.fit(X,y))\n",
    "\n",
    "print(dummymodel.score(X,y))\n",
    "\n",
    "y_pred = dummymodel.predict(X)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "print(y.mean)\n",
    "\n",
    "print(y - y_pred)\n",
    "\n",
    "#the 0.0 is the R-squared --> the mean pricee of the home does not explain any variation\n",
    "#preds are all the same value bc we use the mean \n",
    "\n",
    "# the last is our rediuals; how wrong are we (obseerved - expected); off by 270k for the first observation; bc we are preedicting\n",
    "\n",
    "# this is what we are talking about when we say root mean squared error --> sklearn.metrics see link from jelly \n",
    "\n",
    "# we want these metrics to be \"bad\" the only way to go is up! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start running some regressions  now (after cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.369</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.369</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.141e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 13 Sep 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:25:27</td>     <th>  Log-Likelihood:    </th> <td>-2.6439e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19479</td>      <th>  AIC:               </th>  <td>5.288e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19477</td>      <th>  BIC:               </th>  <td>5.288e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td> 9.838e+04</td> <td> 3899.011</td> <td>   25.232</td> <td> 0.000</td> <td> 9.07e+04</td> <td> 1.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqft_living</th> <td>  199.9927</td> <td>    1.872</td> <td>  106.829</td> <td> 0.000</td> <td>  196.323</td> <td>  203.662</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3657.974</td> <th>  Durbin-Watson:     </th> <td>   1.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8429.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.071</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.407</td>  <th>  Cond. No.          </th> <td>5.97e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.97e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.369\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                 1.141e+04\n",
       "Date:                Tue, 13 Sep 2022   Prob (F-statistic):               0.00\n",
       "Time:                        15:25:27   Log-Likelihood:            -2.6439e+05\n",
       "No. Observations:               19479   AIC:                         5.288e+05\n",
       "Df Residuals:                   19477   BIC:                         5.288e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept    9.838e+04   3899.011     25.232      0.000    9.07e+04    1.06e+05\n",
       "sqft_living   199.9927      1.872    106.829      0.000     196.323     203.662\n",
       "==============================================================================\n",
       "Omnibus:                     3657.974   Durbin-Watson:                   1.971\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8429.710\n",
       "Skew:                           1.071   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.407   Cond. No.                     5.97e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.97e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#why did we choose swft_living; corr & how it impacts the firm \n",
    "base_formula = 'price ~ sqft_living'\n",
    "\n",
    "base_model = ols(formula=base_formula, data=clean_df).fit()\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "#talk about r-sqaured & p-value --> going to add another variable bc...\n",
    "#for each one unit increase in X, Y ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions \n",
    "- Standard Scalar?\n",
    "    - all numeric data in terms of standard deviations --> used when one has metrics on very diff scales ** somethhing we might want to explore ** for multi --> look at diff between scale and unscaled --> when int it is in terms of STD, for every one STD increase in X .. Y does this --> calc what that STD is \n",
    "        - in terms of sqft, what does 1 STD look like (.describe will tell you what mean, its the relationships between mean & std) bc we don't wanna talk about STDs to clients; and we are data scientists, we talk in terms of proximity :give or tak: ! \n",
    "- Get rid of outliers? see above\n",
    "- \"divising a model that can help predict purchase price based on the attributes of the home --> so firms can better prepare their client for the pre-approval process\" \n",
    "- ask about interpretations of sqft coef. \n",
    "- ask about int. of dummy model \n",
    "- ask about zip code int (maybe we talk about this for future insights) \n",
    "\n",
    "\n",
    "overall notes: \n",
    "- give reasons for everything! \n",
    "- meet the checklist! \n",
    "- don't delete code :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('file_name.csv')\n",
    "\n",
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
